{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the sql to encode and decode only some parts of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT name, age, email FROM users\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "# Define the SQL statement\n",
    "sql_statement = \"SELECT name, age, email FROM users\"\n",
    "\n",
    "# Parse the SQL statement using sqlparse\n",
    "parsed_statement = sqlparse.parse(sql_statement)[0]\n",
    "\n",
    "print(parsed_statement)\n",
    "\n",
    "# Extract the field names from the SELECT statement\n",
    "# fields = [str(token) for token in parsed_statement.tokens if token.ttype is sqlparse.tokens.Name]\n",
    "\n",
    "# # Print the field names\n",
    "# print(fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'cli',\n",
       " 'engine',\n",
       " 'exceptions',\n",
       " 'filters',\n",
       " 'format',\n",
       " 'formatter',\n",
       " 'keywords',\n",
       " 'lexer',\n",
       " 'parse',\n",
       " 'parsestream',\n",
       " 'split',\n",
       " 'sql',\n",
       " 'tokens',\n",
       " 'utils']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "dir(sqlparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['select * from foo;', 'select * from bar;']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = 'select * from foo; select * from bar;'\n",
    "statements = sqlparse.split(raw)\n",
    "statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT *\n",
      "FROM foo;\n"
     ]
    }
   ],
   "source": [
    "# Format the first statement and print it out:\n",
    "first = statements[0]\n",
    "print(sqlparse.format(first, reindent=True, keyword_case='upper'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sqlparse' has no attribute 'get_identifiers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m identify \u001b[39m=\u001b[39m sqlparse\u001b[39m.\u001b[39;49mget_identifiers(\u001b[39m'\u001b[39m\u001b[39mselect order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(identify\u001b[39m.\u001b[39mtokens)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sqlparse' has no attribute 'get_identifiers'"
     ]
    }
   ],
   "source": [
    "identify = sqlparse.get_identifiers('select order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc')[0]\n",
    "print(identify.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<DML 'select' at 0x118EAAE60>,\n",
       " <Whitespace ' ' at 0x11990D900>,\n",
       " <IdentifierList 'order....' at 0x119909F50>,\n",
       " <Whitespace ' ' at 0x11990F880>,\n",
       " <Keyword 'from' at 0x11990F8E0>,\n",
       " <Whitespace ' ' at 0x11990F940>,\n",
       " <Identifier 'orders...' at 0x119909CB0>,\n",
       " <Whitespace ' ' at 0x11990FAC0>,\n",
       " <Keyword 'join' at 0x11990FB20>,\n",
       " <Whitespace ' ' at 0x11990FB80>,\n",
       " <Identifier 'revenu...' at 0x119909D90>,\n",
       " <Whitespace ' ' at 0x11990FD00>,\n",
       " <Keyword 'on' at 0x11990FD60>,\n",
       " <Whitespace ' ' at 0x11990FDC0>,\n",
       " <Comparison 'r.orde...' at 0x119909EE0>,\n",
       " <Whitespace ' ' at 0x119934220>,\n",
       " <Keyword 'order ...' at 0x119934280>,\n",
       " <Whitespace ' ' at 0x1199342E0>,\n",
       " <Identifier 'order....' at 0x119909E70>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed = sqlparse.parse('select order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc')[0]\n",
    "parsed.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 0: select\n",
      "Token 1:  \n",
      "Token 2: order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost\n",
      "Token 3:  \n",
      "Token 4: from\n",
      "Token 5:  \n",
      "Token 6: orders o\n",
      "Token 7:  \n",
      "Token 8: join\n",
      "Token 9:  \n",
      "Token 10: revenue r\n",
      "Token 11:  \n",
      "Token 12: on\n",
      "Token 13:  \n",
      "Token 14: r.order_id  = r.order_id\n",
      "Token 15:  \n",
      "Token 16: order by\n",
      "Token 17:  \n",
      "Token 18: order.orderid desc\n"
     ]
    }
   ],
   "source": [
    "# Parsing a SQL statement:\n",
    "parsed = sqlparse.parse('select order.orderid, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc')[0]\n",
    "parsed_tokens = parsed.tokens\n",
    "for i, token in enumerate(parsed_tokens):\n",
    "    print(f\"Token {i}: {token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 14\n",
      "IdentifierList: 1\n",
      "Identifier: 3\n",
      "Comparison: 1\n"
     ]
    }
   ],
   "source": [
    "parsed_tokens = parsed.tokens\n",
    "token_counts = {}\n",
    "\n",
    "for i, token in enumerate(parsed_tokens):\n",
    "    tok_type = type(token).__name__\n",
    "    if tok_type in token_counts:\n",
    "        token_counts[tok_type] += 1\n",
    "    else:\n",
    "        token_counts[tok_type] = 1\n",
    "\n",
    "for tok_type, count in token_counts.items():\n",
    "    print(f\"{tok_type}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rewrite above function but return a list of fields per type in a data table\n",
    "def get_fields(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    token_counts = {}\n",
    "    for i, token in enumerate(parsed_tokens):\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type in token_counts:\n",
    "            token_counts[tok_type].append(token)\n",
    "        else:\n",
    "            token_counts[tok_type] = [token]\n",
    "    #return a dictionary of types and their corresponding tokens in a data table\n",
    "    return token_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fields(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    token_counts = {}\n",
    "    for i, token in enumerate(parsed_tokens):\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace' or tok_type == 'Keyword':\n",
    "            continue\n",
    "        if tok_type in token_counts:\n",
    "            token_counts[tok_type].append(str(token))\n",
    "        else:\n",
    "            token_counts[tok_type] = [str(token)]\n",
    "    #return a list of fields per type in a data table\n",
    "    return token_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: ['SELECT', ' ', ' ', 'FROM', ' ', ' ']\n",
      "IdentifierList: ['first_name, last_name']\n",
      "Identifier: ['employees']\n",
      "Where: ['WHERE salary > 50000']\n"
     ]
    }
   ],
   "source": [
    "from sqlparse import parse\n",
    "\n",
    "# Example SQL query\n",
    "#query = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "query = \"SELECT first_name, last_name FROM employees WHERE salary > 50000\"\n",
    "\n",
    "# Parse the query into tokens\n",
    "parsed = parse(query)[0]\n",
    "\n",
    "# Get the fields in the parsed query\n",
    "fields = get_fields(parsed)\n",
    "\n",
    "# Print out the types and tokens in the data table\n",
    "for tok_type, tokens in fields.items():\n",
    "    print(f\"{tok_type}: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders o', 'revenue r', 'order', 'orderid desc']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifiers = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace':\n",
    "            continue\n",
    "        elif tok_type == 'Keyword':\n",
    "            continue\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier = str(token)\n",
    "            if '.' in identifier:\n",
    "                identifiers.extend(identifier.split('.'))\n",
    "            else:\n",
    "                identifiers.append(identifier)\n",
    "        elif tok_type == 'Name':\n",
    "            identifiers.append(str(token))\n",
    "    return identifiers\n",
    "\n",
    "#sql = \"SELECT first_name, last_name FROM employees WHERE department='Sales'\"\n",
    "sql = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifier_list = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'IdentifierList':\n",
    "            for identifier in token.get_identifiers():\n",
    "                if not isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    continue\n",
    "                identifier_name = identifier.get_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_list.append(identifier_name)\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier_name = token.get_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_list.append(identifier_name)\n",
    "    return identifier_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders o', 'revenue r', 'order', 'orderid desc']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifiers = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace':\n",
    "            continue\n",
    "        elif tok_type == 'Keyword':\n",
    "            continue\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier = str(token)\n",
    "            if '.' in identifier:\n",
    "                identifiers.extend(identifier.split('.'))\n",
    "            else:\n",
    "                identifiers.append(identifier)\n",
    "        elif tok_type == 'Name':\n",
    "            identifiers.append(str(token))\n",
    "    return identifiers\n",
    "\n",
    "#sql = \"SELECT first_name, last_name FROM employees WHERE department='Sales'\"\n",
    "sql = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders o', 'revenue r', 'order', 'orderid desc']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifiers = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'Whitespace':\n",
    "            continue\n",
    "        elif tok_type == 'Keyword':\n",
    "            continue\n",
    "        elif tok_type == 'Identifier':\n",
    "            identifier = str(token)\n",
    "            if '.' in identifier:\n",
    "                identifiers.extend(identifier.split('.'))\n",
    "            else:\n",
    "                identifiers.append(identifier)\n",
    "        elif tok_type == 'Name':\n",
    "            identifiers.append(str(token))\n",
    "    return identifiers\n",
    "\n",
    "#sql = \"SELECT first_name, last_name FROM employees WHERE department='Sales'\"\n",
    "sql = \"select order.order_id, order.order_name, revenue.order_id, r.product_name, revenue.cost from orders o join revenue r on r.order_id  = r.order_id order by order.orderid desc\"\n",
    "\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['column1', 'column2', 'table1']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "sql = \"SELECT column1, column2 FROM table1 WHERE column3 = 'value'\"\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "identifiers = get_identifiers(parsed)\n",
    "print(identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifier_list(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    identifier_list = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type == 'IdentifierList':\n",
    "            for identifier in token.get_identifiers():\n",
    "                if not isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    continue\n",
    "                identifier_name = identifier.get_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_list.append(identifier_name)\n",
    "    return identifier_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['column1', 'column2']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "sql = \"SELECT column1, column2 FROM table1 WHERE column3 = 'value'\"\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "identifier_list = get_identifier_list(parsed)\n",
    "print(identifier_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tok_types(parsed):\n",
    "    parsed_tokens = parsed.tokens\n",
    "    tok_types = []\n",
    "    for token in parsed_tokens:\n",
    "        tok_type = type(token).__name__\n",
    "        if tok_type in ['Identifier', 'Comparison', 'IdentifierList', 'Where']:\n",
    "            tok_types.append(tok_type)\n",
    "    return tok_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IdentifierList', 'Identifier', 'Where']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "query = \"SELECT first_name, last_name FROM employees WHERE salary > 50000\"\n",
    "parsed_query = sqlparse.parse(query)[0]\n",
    "tok_types = get_tok_types(parsed_query)\n",
    "print(tok_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Identifier 'elect ...' at 0x119F04740>,\n",
       " <Whitespace ' ' at 0x11AB80280>,\n",
       " <Integer '10' at 0x11AB801C0>,\n",
       " <Whitespace ' ' at 0x11AB825C0>,\n",
       " <IdentifierList 'getdat...' at 0x11AADB4C0>,\n",
       " <Whitespace ' ' at 0x11AB81900>,\n",
       " <Keyword 'from' at 0x11AB827A0>,\n",
       " <Whitespace ' ' at 0x11AB818A0>,\n",
       " <Identifier 'orders...' at 0x119F04200>,\n",
       " <Whitespace ' ' at 0x11AAB41C0>,\n",
       " <Keyword 'join' at 0x11AAB4040>,\n",
       " <Whitespace ' ' at 0x11AAB46A0>,\n",
       " <Identifier 'revenu...' at 0x119F044A0>,\n",
       " <Whitespace ' ' at 0x11AAB4DC0>,\n",
       " <Keyword 'on' at 0x11AAB4D60>,\n",
       " <Whitespace ' ' at 0x11AAB50C0>,\n",
       " <Comparison 'o.orde...' at 0x11AADB680>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "query = \"Select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "parsed_query = sqlparse.parse(query)[0]\n",
    "parsed_query.tokens\n",
    "#print(parsed_query.tokens)\n",
    "# tok_types = get_identifiers(query)\n",
    "# print(tok_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Token' object has no attribute 'next_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[235], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n\u001b[1;32m     34\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSelect top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(extract_columns_and_tables(query))\n",
      "Cell \u001b[0;32mIn[235], line 28\u001b[0m, in \u001b[0;36mextract_columns_and_tables\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# If the token is a join keyword, get the table name from the next token\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39melif\u001b[39;00m token\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjoin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m         tables\u001b[39m.\u001b[39madd(token\u001b[39m.\u001b[39;49mnext_token\u001b[39m.\u001b[39mnext_token\u001b[39m.\u001b[39mget_real_name())\n\u001b[1;32m     30\u001b[0m \u001b[39m# Return the list of column and table names\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Token' object has no attribute 'next_token'"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_columns_and_tables(sql):\n",
    "    # Parse the SQL statement into tokens\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "    # Initialize empty lists to store column and table names\n",
    "    results = []\n",
    "    tables = set()\n",
    "\n",
    "    # Loop through all tokens in the parsed SQL statement\n",
    "    for token in parsed.flatten():\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        # If the token is a column or table name, add it to the results list\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            # Check if the previous token is a period, indicating a table alias\n",
    "            if token.parent and token.parent.value == '.':\n",
    "                table_name = token.parent.get_previous_sibling().get_real_name()\n",
    "                column_name = token.get_real_name()\n",
    "                results.append(table_name + '.' + column_name)\n",
    "                tables.add(table_name)\n",
    "            else:\n",
    "                results.append(token.get_real_name())\n",
    "        # If the token is a join keyword, get the table name from the next token\n",
    "        elif token.value.lower() == 'join':\n",
    "            tables.add(token.next_token.next_token.get_real_name())\n",
    "\n",
    "    # Return the list of column and table names\n",
    "    return list(results) + list(tables)\n",
    "\n",
    "\n",
    "query = \"Select top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "print(extract_columns_and_tables(query))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Token' object has no attribute 'next_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[236], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n\u001b[1;32m     34\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSelect top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mprint\u001b[39m(extract_columns_and_tables(query))\n",
      "Cell \u001b[0;32mIn[236], line 28\u001b[0m, in \u001b[0;36mextract_columns_and_tables\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[39m# If the token is a join keyword, get the table name from the next token\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39melif\u001b[39;00m token\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mjoin\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m         tables\u001b[39m.\u001b[39madd(token\u001b[39m.\u001b[39;49mnext_token\u001b[39m.\u001b[39mnext_token\u001b[39m.\u001b[39mget_real_name())\n\u001b[1;32m     30\u001b[0m \u001b[39m# Return the list of column and table names\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(results) \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(tables)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Token' object has no attribute 'next_token'"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_columns_and_tables(sql):\n",
    "    # Parse the SQL statement into tokens\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "\n",
    "    # Initialize empty lists to store column and table names\n",
    "    results = []\n",
    "    tables = set()\n",
    "\n",
    "    # Loop through all tokens in the parsed SQL statement\n",
    "    for token in parsed.flatten():\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        # If the token is a column or table name, add it to the results list\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            # Check if the previous token is a period, indicating a table alias\n",
    "            if token.parent and token.parent.value == '.':\n",
    "                table_name = token.parent.get_previous_sibling().get_real_name()\n",
    "                column_name = token.get_real_name()\n",
    "                results.append(table_name + '.' + column_name)\n",
    "                tables.add(table_name)\n",
    "            else:\n",
    "                results.append(token.get_real_name())\n",
    "        # If the token is a join keyword, get the table name from the next token\n",
    "        elif token.value.lower() == 'join':\n",
    "            tables.add(token.next_token.next_token.get_real_name())\n",
    "\n",
    "    # Return the list of column and table names\n",
    "    return list(results) + list(tables)\n",
    "\n",
    "\n",
    "query = \"Select top 10 getdate(), o.order_number, client_name, sum(r.net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "print(extract_columns_and_tables(query))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n",
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "lst = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Mask string literals in the list\n",
    "masked_lst = mask_string_literals(lst)\n",
    "print(masked_lst)  # Output: [\"'first_name'\", 'employees', \"'last_name'\", \"'salary'\", \"'department'\"]\n",
    "\n",
    "# Unmask string literals in the list\n",
    "unmasked_lst = unmask_string_literals(masked_lst)\n",
    "print(unmasked_lst)  # Output: ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# # Apply mask to SQL code\n",
    "# sql = \"SELECT first_name FROM employees WHERE department = 'Sales'\"\n",
    "# masked_sql = apply_mask_to_sql(sql)\n",
    "# print(masked_sql)  # Output: \"SELECT first_name FROM employees WHERE department = ''Sales''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n",
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "lst = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Mask string literals in the list\n",
    "masked_lst = mask_string_literals(lst)\n",
    "print(masked_lst)  # Output: [\"'first_name'\", 'employees', \"'last_name'\", \"'salary'\", \"'department'\"]\n",
    "\n",
    "# Unmask string literals in the list\n",
    "unmasked_lst = unmask_string_literals(masked_lst)\n",
    "print(unmasked_lst)  # Output: ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# # Apply mask to SQL code\n",
    "# sql = \"SELECT first_name FROM employees WHERE department = 'Sales'\"\n",
    "# masked_sql = apply_mask_to_sql(sql)\n",
    "# print(masked_sql)  # Output: \"SELECT first_name FROM employees WHERE department = ''Sales''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n",
      "['first_name', 'employees', 'last_name', 'salary', 'department']\n"
     ]
    }
   ],
   "source": [
    "lst = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Mask string literals in the list\n",
    "masked_lst = mask_string_literals(lst)\n",
    "print(masked_lst)  # Output: [\"'first_name'\", 'employees', \"'last_name'\", \"'salary'\", \"'department'\"]\n",
    "\n",
    "# Unmask string literals in the list\n",
    "unmasked_lst = unmask_string_literals(masked_lst)\n",
    "print(unmasked_lst)  # Output: ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# # Apply mask to SQL code\n",
    "# sql = \"SELECT first_name FROM employees WHERE department = 'Sales'\"\n",
    "# masked_sql = apply_mask_to_sql(sql)\n",
    "# print(masked_sql)  # Output: \"SELECT first_name FROM employees WHERE department = ''Sales''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'o', None, 'sum', 'top', 'client_name', 'r', 'getdate']\n"
     ]
    }
   ],
   "source": [
    "#Alles zusammen - Working for parsing fields from a sql statement. Decide to do it modularly, not sure why but this works. That is why\n",
    "#works for where!!!\n",
    "import sqlparse\n",
    "\n",
    "def get_where_fields(query):\n",
    "    parsed_query = sqlparse.parse(query)[0]\n",
    "    where_clause = None\n",
    "    for token in parsed_query.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Where):\n",
    "            where_clause = token\n",
    "            break\n",
    "    if not where_clause:\n",
    "        return []\n",
    "    fields = []\n",
    "    for token in where_clause.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Comparison):\n",
    "            left = token.left\n",
    "            if isinstance(left, sqlparse.sql.Identifier):\n",
    "                fields.append(left.get_name())\n",
    "            elif isinstance(left, sqlparse.sql.Function):\n",
    "                fields.append(left.tokens[0].get_name())\n",
    "    return fields\n",
    "\n",
    "# Works for identifiers\n",
    "def get_identifiers(query):\n",
    "    parsed_tokens = sqlparse.parse(query)[0]\n",
    "    identifier_set = set()\n",
    "    for token in parsed_tokens:\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                identifier_name = identifier.get_name()\n",
    "                if '.' in identifier_name:\n",
    "                    identifier_name = identifier_name.split('.')[1]\n",
    "                identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            identifier_name = token.get_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            identifier_name = token.get_name()\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            identifier_name = token.get_name()\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "    return list(identifier_set)\n",
    "\n",
    "import sqlparse\n",
    "#query = \"SELECT first_name, last_name FROM employees WHERE salary > 50000 AND department = 'Sales'\"\n",
    "query =\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "identifiers = get_identifiers(query)\n",
    "# where_fields = get_where_fields(query)\n",
    "# list_of_fields = identifiers + where_fields\n",
    "# print(list_of_fields)\n",
    "print(identifiers)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Finally working for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'revenue', 'order_id', 'orders', 'client_name']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "    \n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        # If the token is a function, skip it\n",
    "        if isinstance(token, sqlparse.sql.Function) or token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    identifier_name = identifier.get_real_name()\n",
    "                    if '.' in identifier_name:\n",
    "                        identifier_name = identifier_name.split('.')[1]\n",
    "                    identifier_set.add(identifier_name)\n",
    "        # If the token is a comparison operator, get the column name\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            identifier_name = token.left.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            identifier_name = token.get_real_name()\n",
    "            if '.' in identifier_name:\n",
    "                identifier_name = identifier_name.split('.')[1]\n",
    "            identifier_set.add(identifier_name)\n",
    "    return list(identifier_set)\n",
    "\n",
    "\n",
    "\n",
    "query =\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in\"\n",
    "identifiers = get_identifiers(query)\n",
    "print(identifiers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking and Demasking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def masking(list_of_fields, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and a SQL string as input and replaces the words in the SQL string with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original words and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each word in the list of words\n",
    "    for word in list_of_fields:\n",
    "        # Generate a random word to replace the original word\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(word)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[word] = random_word\n",
    "        \n",
    "        # Replace the original word with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(word), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map\n",
    "\n",
    "\n",
    "def demasking(word_map, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a word map and a masked SQL string as input and replaces the masked words with their original words.\n",
    "    \"\"\"\n",
    "    # Loop through each key-value pair in the word map\n",
    "    for original_word, masked_word in word_map.items():\n",
    "        # Replace the masked word with the original word in the SQL string\n",
    "        sql_string = re.sub(r'\\b{}\\b'.format(masked_word), original_word, sql)\n",
    "    \n",
    "    # Return the demasked SQL string\n",
    "    return sql_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked SQL string: select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in\n",
      "Word map: {'first_name': 'shyuckvdgw', 'employees': 'uudyfsqyx', 'last_name': 'rvecpyxir', 'salary': 'yqrvxk', 'department': 'uwlebjbjak'}\n",
      "Demasked SQL string: select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in\n"
     ]
    }
   ],
   "source": [
    "# Define the list of words to mask\n",
    "words_to_mask = ['first_name', 'employees', 'last_name', 'salary', 'department']\n",
    "\n",
    "# Define the SQL string to mask\n",
    "sql = \"SELECT first_name, last_name FROM employees WHERE salary > 50000 AND department = 'Sales'\"\n",
    "\n",
    "# Mask the SQL string\n",
    "masked_sql_string, word_map = masking(words_to_mask, query)\n",
    "\n",
    "# Print the masked SQL string and the word map\n",
    "print(\"Masked SQL string:\", masked_sql_string)\n",
    "print(\"Word map:\", word_map)\n",
    "\n",
    "# Demask the SQL string\n",
    "demasked_sql_string = demasking(word_map, masked_sql_string)\n",
    "\n",
    "# Print the demasked SQL string\n",
    "print(\"Demasked SQL string:\", demasked_sql_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked SQL string: select ciw 10 ufbdnsy(), wjdonbpitghk, ndyykbwdxur, tcv(net_revenue) from orders x join revenue y on x.order_id = y.order_id\n",
      "Word map: {'client_name': 'ndyykbwdxur', 'r': 'y', 'top': 'ciw', 'order_number': 'wjdonbpitghk', 'sum': 'tcv', 'o': 'x', 'getdate': 'ufbdnsy'}\n"
     ]
    }
   ],
   "source": [
    "# Define the list of words to mask\n",
    "words_to_mask = ['client_name', 'r', 'top', 'order_number', 'sum', 'o', 'getdate']\n",
    "\n",
    "# Define the SQL string to mask\n",
    "query = \"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id\"\n",
    "\n",
    "# Mask the SQL string\n",
    "masked_sql_string, word_map = masking(words_to_mask, query)\n",
    "\n",
    "# Print the masked SQL string and the word map\n",
    "print(\"Masked SQL string:\", masked_sql_string)\n",
    "print(\"Word map:\", word_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_number', 'revenue', 'order_id', 'revenue_order', 'orders', 'client_name']\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "\n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    def process_identifier(token, identifier_set):\n",
    "        identifier_name = token.get_real_name()\n",
    "        if '.' in identifier_name:\n",
    "            identifier_name = identifier_name.split('.')[1]\n",
    "        identifier_set.add(identifier_name)\n",
    "\n",
    "    def process_function_arguments(token, identifier_set):\n",
    "        if isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def add_identifiers_from_function(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def process_where(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            if isinstance(subtoken, sqlparse.sql.Comparison):\n",
    "                process_identifier(subtoken.left, identifier_set)\n",
    "            elif isinstance(subtoken, sqlparse.sql.Identifier):\n",
    "                process_identifier(subtoken, identifier_set)\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            add_identifiers_from_function(token, identifier_set)\n",
    "            continue\n",
    "        if token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            process_identifier(token.left, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            process_where(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "    return list(identifier_set)\n",
    "\n",
    "query = \"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_order in ('3245', '34244',  '4532')\"\n",
    "identifiers = get_identifiers(query)\n",
    "print(identifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'identifiers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39m# Return the masked SQL string and the word map\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m sql, word_map\n\u001b[0;32m---> 26\u001b[0m masked_sql_wordmap \u001b[39m=\u001b[39m masking(identifiers, query)\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(masked_sql_wordmap)\n\u001b[1;32m     29\u001b[0m \u001b[39m# Still missing the Where cluse pick up - I am missing revenue_order field. This needs to be added to identifiers function. Here I am then this is ready. \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'identifiers' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def masking(identifiers, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of identifiers and an SQL query as input, and replaces the identifiers in the SQL query with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original identifiers and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each identifier in the list of identifiers\n",
    "    for identifier in identifiers:\n",
    "        # Generate a random word to replace the original identifier\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(identifier)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[identifier] = random_word\n",
    "        \n",
    "        # Replace the original identifier with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(identifier), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map\n",
    "\n",
    "\n",
    "masked_sql_wordmap = masking(identifiers, query)\n",
    "print(masked_sql_wordmap)\n",
    "\n",
    "# Still missing the Where cluse pick up - I am missing revenue_order field. This needs to be added to identifiers function. Here I am then this is ready. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "\n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    def process_identifier(token, identifier_set):\n",
    "        identifier_name = token.get_real_name()\n",
    "        if '.' in identifier_name:\n",
    "            identifier_name = identifier_name.split('.')[1]\n",
    "        identifier_set.add(identifier_name)\n",
    "\n",
    "    def process_function_arguments(token, identifier_set):\n",
    "        if isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def add_identifiers_from_function(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def process_where(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            if isinstance(subtoken, sqlparse.sql.Comparison):\n",
    "                process_identifier(subtoken.left, identifier_set)\n",
    "            elif isinstance(subtoken, sqlparse.sql.Identifier):\n",
    "                process_identifier(subtoken, identifier_set)\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            add_identifiers_from_function(token, identifier_set)\n",
    "            continue\n",
    "        if token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            process_identifier(token.left, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            process_where(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "    return list(identifier_set)\n",
    "\n",
    "def sql_masking(identifiers, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of identifiers and an SQL query as input, and replaces the identifiers in the SQL query with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original identifiers and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each identifier in the list of identifiers\n",
    "    for identifier in identifiers:\n",
    "        # Generate a random word to replace the original identifier\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(identifier)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[identifier] = random_word\n",
    "        \n",
    "        # Replace the original identifier with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(identifier), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_number in ('2345', '9908', '6671')\"\n",
    "sql2=\"\"\"select K.a,K.b from (select H.b from (select G.c from (select F.d from (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orders', 'order_number', 'client_name', 'revenue_number', 'order_id', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "list_of_fields = get_identifiers(sql)\n",
    "print(list_of_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select top 10 getdate(), ffjoiuesdgyx, fjcgirovzue, sum(net_revenue) from bjrpjh o join akplyhv r on o.stlsxbqe = r.stlsxbqe where zrprazzgybxcri in ('2345', '9908', '6671')\n"
     ]
    }
   ],
   "source": [
    "masked_sql, word_map  = sql_masking(list_of_fields, sql)\n",
    "print(masked_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demask fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demasking(word_map, masked_sql):\n",
    "    \"\"\"\n",
    "    This function takes in a word map and a masked SQL string as input and replaces the masked words with their original words.\n",
    "    \"\"\"\n",
    "    # Loop through each key-value pair in the word map\n",
    "    for original_word, masked_word in word_map.items():\n",
    "        # Replace the masked word with the original word in the SQL string\n",
    "        sql_string = re.sub(r'\\b{}\\b'.format(masked_word), original_word, sql)\n",
    "    \n",
    "    # Return the demasked SQL string\n",
    "    return sql_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demasked SQL string: select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_number in ('2345', '9908', '6671')\n"
     ]
    }
   ],
   "source": [
    "# Demask the SQL string\n",
    "demasked_sql = demasking(word_map, masked_sql)\n",
    "\n",
    "# Print the demasked SQL string\n",
    "print(\"Demasked SQL string:\", demasked_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# loads .env file located in the current directory\n",
    "load_dotenv() \n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sql=\"mysql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_dialectify(to_sql, masked_sql):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": 'You are an expert SQL developer that is proficient in MS SQL Server, MySQL, Oracle, PostgreSQL, SQLite, Snowflake SQL dialects.'},\n",
    "            {\"role\": \"system\", \"content\": 'Only return the converted sql code and do not explain the conversion process.'},\n",
    "            {\"role\": \"system\", \"content\": 'Check for the correctness of the entered SQL code. And make updates if necessary. List the changes succinctly in the chat.'},\n",
    "            {\"role\": \"system\", \"content\": 'Let''s think step by step.'},\n",
    "            {\"role\": \"user\", \"content\": f'Detect the dialect of the following SQL code: \"{masked_sql}\"'},\n",
    "            {\"role\": \"system\", \"content\": f'Check and fix errors for the top common SQL syntax mistakes for the detected dialect. List updated parts of the following SQL code: \"{masked_sql}\"'},\n",
    "            {\"role\": \"user\", \"content\": f'Convert the updated SQL code from detected dialect to \"{to_sql}\": \"\\n\\n{masked_sql}\"'}\n",
    "        ]\n",
    "    )\n",
    "    converted_sql = completion.choices[0].message.content\n",
    "    return converted_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a Microsoft SQL Server specific syntax. In MySQL, we have to use LIMIT instead of TOP. Also, we don't have GETDATE() function in MySQL. Try the following code instead:\n",
      "\n",
      "```\n",
      "SELECT NOW(), blkyovxmofvp, imfutirkbqw, SUM(net_revenue)\n",
      "FROM ciwvio o \n",
      "JOIN rmegrla r ON o.zicjjvre = r.zicjjvre \n",
      "WHERE ejammpwncomqtc IN ('2345', '9908', '6671')\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Note that `NOW()` returns the current date and time in MySQL. If you only want the current date, you can use `CURDATE()` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "masked_converted_sql = sql_dialectify(to_sql, masked_sql)\n",
    "# Display the converted SQL code\n",
    "print(masked_converted_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add _view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original SQL:\n",
      " \n",
      "    select K.a,K.b from (select H.b from (select G.c from (select F.d from\n",
      "    (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;\n",
      "    \n",
      "Updated SQL:\n",
      " \n",
      "    select K_view.a_view,K_view.b_view from (select H.b_view from (select G.c from (select F.d from\n",
      "    (select E.e from A, B, C, D, E), F), G), H), I_view, J_view, K_view order b_viewy 1,2;\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML, Name\n",
    "\n",
    "\n",
    "def extract_table_identifiers(token_stream):\n",
    "    for item in token_stream:\n",
    "        if isinstance(item, Identifier):\n",
    "            yield item.get_real_name()\n",
    "        elif isinstance(item, IdentifierList):\n",
    "            for identifier in item.get_identifiers():\n",
    "                if isinstance(identifier, Identifier):\n",
    "                    yield identifier.get_real_name()\n",
    "\n",
    "\n",
    "def append_view_to_tables(sql, tables):\n",
    "    updated_sql = sql\n",
    "    for table in tables:\n",
    "        updated_sql = updated_sql.replace(table, f\"{table}_view\")\n",
    "    return updated_sql\n",
    "\n",
    "\n",
    "def extract_tables(sql):\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "    token_stream = extract_table_identifiers(parsed.tokens)\n",
    "    table_set = set()\n",
    "\n",
    "    for token in token_stream:\n",
    "        if token.upper() != \"AS\":\n",
    "            table_set.add(token)\n",
    "\n",
    "    return list(table_set)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sql = \"\"\"\n",
    "    select K.a,K.b from (select H.b from (select G.c from (select F.d from\n",
    "    (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;\n",
    "    \"\"\"\n",
    "\n",
    "    tables = extract_tables(sql)\n",
    "    updated_sql = append_view_to_tables(sql, tables)\n",
    "\n",
    "    print('Original SQL:\\n', sql)\n",
    "    print('Updated SQL:\\n', updated_sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Token' object has no attribute 'get_real_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      4\u001b[0m     sql \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39m    select K.a,K.b from (select H.b from (select G.c from (select F.d from\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39m    (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     tables \u001b[39m=\u001b[39m extract_tables(sql)\n\u001b[1;32m     10\u001b[0m     updated_sql \u001b[39m=\u001b[39m append_view_to_tables(sql, tables)\n\u001b[1;32m     11\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTables:\u001b[39m\u001b[39m'\u001b[39m, tables)\n",
      "Cell \u001b[0;32mIn[8], line 29\u001b[0m, in \u001b[0;36mextract_tables\u001b[0;34m(sql)\u001b[0m\n\u001b[1;32m     26\u001b[0m token_stream \u001b[39m=\u001b[39m extract_table_identifiers(parsed\u001b[39m.\u001b[39mtokens)\n\u001b[1;32m     27\u001b[0m table_set \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m token_stream:\n\u001b[1;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mupper() \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAS\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     31\u001b[0m         table_set\u001b[39m.\u001b[39madd(token)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mextract_table_identifiers\u001b[0;34m(token_stream)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, IdentifierList):\n\u001b[1;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m identifier \u001b[39min\u001b[39;00m item\u001b[39m.\u001b[39mget_identifiers():\n\u001b[0;32m---> 12\u001b[0m         \u001b[39myield\u001b[39;00m identifier\u001b[39m.\u001b[39;49mget_real_name()\n\u001b[1;32m     13\u001b[0m \u001b[39melif\u001b[39;00m item\u001b[39m.\u001b[39mttype \u001b[39mis\u001b[39;00m Name:\n\u001b[1;32m     14\u001b[0m     \u001b[39myield\u001b[39;00m item\u001b[39m.\u001b[39mvalue\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Token' object has no attribute 'get_real_name'"
     ]
    }
   ],
   "source": [
    "#sql=\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_number in ('2345', '9908', '6671')\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sql = \"\"\"\n",
    "    select K.a,K.b from (select H.b from (select G.c from (select F.d from\n",
    "    (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;\n",
    "    \"\"\"\n",
    "\n",
    "    tables = extract_tables(sql)\n",
    "    updated_sql = append_view_to_tables(sql, tables)\n",
    "    print('Tables:', tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_and_code(input_string):\n",
    "    \"\"\"\n",
    "    This function takes in a string as input and returns two strings - text and code.\n",
    "    The code is the portion within triple quotes, and the text is the rest of the string.\n",
    "    \"\"\"\n",
    "    # Find the index of the first occurrence of triple quotes\n",
    "    start_index = input_string.find('\"\"\"')\n",
    "    \n",
    "    # If triple quotes are not found, return the entire string as text and an empty string as code\n",
    "    if start_index == -1:\n",
    "        return input_string.strip(), \"\"\n",
    "    \n",
    "    # Find the index of the second occurrence of triple quotes\n",
    "    end_index = input_string.find('\"\"\"', start_index + 3)\n",
    "    \n",
    "    # If the second occurrence of triple quotes is not found, return the entire string as text and an empty string as code\n",
    "    if end_index == -1:\n",
    "        return input_string.strip(), \"\"\n",
    "    \n",
    "    # Extract the text before the triple quotes and the code between the triple quotes\n",
    "    text = input_string[:start_index].strip()\n",
    "    code = input_string[start_index+3:end_index].strip()\n",
    "    \n",
    "    return text, code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "The SQL code cannot be directly converted to MySQL as it contains a few syntax errors specific to MS SQL Server. Here are the corrected SQL code to be used for the conversion:\n",
      "\n",
      "```mysql\n",
      "SELECT CAST(NOW() AS DATE), xzxpaynvykdy, zaoejvuuefv, SUM(net_revenue) \n",
      "FROM fhwdiv o \n",
      "JOIN zhmpjpo r \n",
      "ON o.tzmiorqu = r.tzmiorqu \n",
      "WHERE eazuotfoyhdfcx IN ('2345', '9908', '6671')\n",
      "LIMIT 10;\n",
      "```\n",
      "\n",
      "Code:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_string = \"The SQL code cannot be directly converted to MySQL as it contains a few syntax errors specific to MS SQL Server. Here are the corrected SQL code to be used for the conversion:\\n\\n```mysql\\nSELECT CAST(NOW() AS DATE), xzxpaynvykdy, zaoejvuuefv, SUM(net_revenue) \\nFROM fhwdiv o \\nJOIN zhmpjpo r \\nON o.tzmiorqu = r.tzmiorqu \\nWHERE eazuotfoyhdfcx IN ('2345', '9908', '6671')\\nLIMIT 10;\\n```\"\n",
    "\n",
    "text, code = split_text_and_code(input_string)\n",
    "\n",
    "print(\"Text:\")\n",
    "print(text)\n",
    "\n",
    "print(\"\\nCode:\")\n",
    "print(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select top 10 getdate(), aqqddmhwgxte, zfzxhmzsvdb, sum(net_revenue) from tckvql o join udghcyk r on o.devgbttq = r.devgbttq where edgygahbmavogp in ('2345', '9908', '6671')\n",
      "{'revenue': 'udghcyk', 'client_name': 'zfzxhmzsvdb', 'revenue_number': 'edgygahbmavogp', 'orders': 'tckvql', 'order_id': 'devgbttq', 'order_number': 'aqqddmhwgxte'}\n",
      "['revenue', 'client_name', 'revenue_number', 'orders', 'order_id', 'order_number']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import os\n",
    "import streamlit as st\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "# loads .env file located in the current directory\n",
    "load_dotenv() \n",
    "\n",
    "import sqlparse\n",
    "import random\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML, Name\n",
    "to_sql = \"Snowflake\"\n",
    "sql=\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_number in ('2345', '9908', '6671')\"\n",
    "\n",
    "# Extract fields for masking - identifier_set\n",
    "\n",
    "def get_identifiers(sql):\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "\n",
    "    reserved_words = ['TOP', 'SELECT', 'FROM', 'WHERE', 'JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER', 'ON', 'GROUP', 'BY', 'HAVING', 'ORDER', 'ASC', 'DESC']\n",
    "\n",
    "    def process_identifier(token, identifier_set):\n",
    "        identifier_name = token.get_real_name()\n",
    "        if '.' in identifier_name:\n",
    "            identifier_name = identifier_name.split('.')[1]\n",
    "        identifier_set.add(identifier_name)\n",
    "\n",
    "    def process_function_arguments(token, identifier_set):\n",
    "        if isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def add_identifiers_from_function(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            process_function_arguments(subtoken, identifier_set)\n",
    "\n",
    "    def process_where(token, identifier_set):\n",
    "        for subtoken in token.tokens:\n",
    "            if isinstance(subtoken, sqlparse.sql.Comparison):\n",
    "                process_identifier(subtoken.left, identifier_set)\n",
    "            elif isinstance(subtoken, sqlparse.sql.Identifier):\n",
    "                process_identifier(subtoken, identifier_set)\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Function):\n",
    "            add_identifiers_from_function(token, identifier_set)\n",
    "            continue\n",
    "        if token.value.upper() in reserved_words:\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            process_identifier(token.left, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            process_where(token, identifier_set)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token, identifier_set)\n",
    "    return list(identifier_set)\n",
    "\n",
    "def sql_masking(identifiers, sql):\n",
    "    \"\"\"\n",
    "    This function takes in a list of identifiers and an SQL query as input, and replaces the identifiers in the SQL query with random words.\n",
    "    \"\"\"\n",
    "    # Create a dictionary to store the mapping between original identifiers and masked words\n",
    "    word_map = {}\n",
    "    \n",
    "    # Loop through each identifier in the list of identifiers\n",
    "    for identifier in identifiers:\n",
    "        # Generate a random word to replace the original identifier\n",
    "        random_word = ''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=len(identifier)))\n",
    "        \n",
    "        # Add the mapping to the dictionary\n",
    "        word_map[identifier] = random_word\n",
    "        \n",
    "        # Replace the original identifier with the random word in the SQL string\n",
    "        sql = re.sub(r'\\b{}\\b'.format(identifier), random_word, sql)\n",
    "    \n",
    "    # Return the masked SQL string and the word map\n",
    "    return sql, word_map\n",
    "\n",
    "def sql_dialectify(to_sql, masked_sql):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": 'You are an expert SQL developer that is proficient in MS SQL Server, MySQL, Oracle, PostgreSQL, SQLite, Snowflake SQL dialects.'},\n",
    "            {\"role\": \"system\", \"content\": 'Only return the converted sql code and do not explain the conversion process.'},\n",
    "            {\"role\": \"system\", \"content\": 'Check for the correctness of the entered SQL code. And make updates if necessary. List the changes succinctly in the chat.'},\n",
    "            {\"role\": \"system\", \"content\": 'Let''s think step by step.'},\n",
    "            {\"role\": \"user\", \"content\": f'Detect the dialect of the following SQL code: \"{masked_sql}\"'},\n",
    "            {\"role\": \"system\", \"content\": f'Check and fix errors for the top common SQL syntax mistakes for the detected dialect. List updated parts of the following SQL code: \"{masked_sql}\"'},\n",
    "            {\"role\": \"user\", \"content\": f'Convert the updated SQL code from detected dialect to \"{to_sql}\": \"\\n\\n{masked_sql}\"'}\n",
    "        ]\n",
    "    )\n",
    "    converted_sql = completion.choices[0].message.content\n",
    "    return converted_sql\n",
    "\n",
    "# Demask Converted SQL\n",
    "\n",
    "def demasking(word_map, masked_sql):\n",
    "    \"\"\"\n",
    "    This function takes in a word map and a masked SQL string as input and replaces the masked words with their original words.\n",
    "    \"\"\"\n",
    "    demasked_sql = masked_sql\n",
    "\n",
    "    # Loop through each key-value pair in the word map\n",
    "    for original_word, masked_word in word_map.items():\n",
    "        # Replace the masked word with the original word in the SQL string\n",
    "        demasked_sql = re.sub(r'\\b{}\\b'.format(masked_word), original_word, demasked_sql)\n",
    "    \n",
    "    # Return the demasked SQL string\n",
    "    return demasked_sql\n",
    "\n",
    "\n",
    "# Convert SQL dialect\n",
    "\n",
    "list_of_fields = get_identifiers(sql)\n",
    "masked_sql, word_map = sql_masking(list_of_fields, sql)\n",
    "print(masked_sql)\n",
    "print(word_map)\n",
    "print(list_of_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'revenue': 'udghcyk', 'client_name': 'zfzxhmzsvdb', 'revenue_number': 'edgygahbmavogp', 'orders': 'tckvql', 'order_id': 'devgbttq', 'order_number': 'aqqddmhwgxte'}\n",
      "select top 10 getdate(), aqqddmhwgxte, zfzxhmzsvdb, sum(net_revenue) from tckvql o join udghcyk r on o.devgbttq = r.devgbttq where edgygahbmavogp in ('2345', '9908', '6671')\n",
      "This query can be converted from MS SQL Server to Snowflake by changing \"TOP\" clause to \"LIMIT\" and removing \"getdate()\" function, as it is not supported in Snowflake. Here's the converted code:\n",
      "\n",
      "```\n",
      "SELECT aqqddmhwgxte, zfzxhmzsvdb, SUM(net_revenue)\n",
      "FROM tckvql o \n",
      "JOIN udghcyk r ON o.devgbttq = r.devgbttq \n",
      "WHERE edgygahbmavogp IN ('2345', '9908', '6671')\n",
      "LIMIT 10;\n",
      "```\n",
      "This query can be converted from MS SQL Server to Snowflake by changing \"TOP\" clause to \"LIMIT\" and removing \"getdate()\" function, as it is not supported in Snowflake. Here's the converted code:\n",
      "\n",
      "```\n",
      "SELECT order_number, client_name, SUM(net_revenue)\n",
      "FROM orders o \n",
      "JOIN revenue r ON o.order_id = r.order_id \n",
      "WHERE revenue_number IN ('2345', '9908', '6671')\n",
      "LIMIT 10;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "masked_converted_sql = sql_dialectify(to_sql, masked_sql)\n",
    "demasked_sql = demasking(word_map, masked_converted_sql)\n",
    "print(word_map)\n",
    "print(masked_sql)\n",
    "print(masked_converted_sql)\n",
    "print(demasked_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Start - adding it all into a single function\n",
    "- Toggle to add _view to the returned results. Encode and decode has to be done (Run both find table and add _view functions in a single function together. The idea should be to find the tables and append _view at that time and not call them and append them back by word. I guess I can Mask them as I extract the words as well. That is probably why the masking is not working as intended. So one function to do many things.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql=\"select top 10 getdate(), order_number, client_name, sum(net_revenue) from orders o join revenue r on o.order_id = r.order_id where revenue_number in ('2345', '9908', '6671')\"\n",
    "sql2=\"\"\"select K.a,K.b from (select H.b from (select G.c from (select F.d from (select E.e from A, B, C, D, E), F), G), H), I, J, K order by 1,2;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import os\n",
    "import streamlit as st\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "# loads .env file located in the current directory\n",
    "load_dotenv() \n",
    "\n",
    "import sqlparse\n",
    "import random\n",
    "from sqlparse.sql import IdentifierList, Identifier\n",
    "from sqlparse.tokens import Keyword, DML, Name\n",
    "\n",
    "import time\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "import re\n",
    "\n",
    "def parse_sql(sql):\n",
    "    \"\"\"\n",
    "    This function takes in an SQL query as input and returns a list of identifiers.\n",
    "    \"\"\"\n",
    "    def process_identifier(token):\n",
    "        identifier_name = token.get_real_name()\n",
    "        if '.' in identifier_name:\n",
    "            identifier_name = identifier_name.split('.')[1]\n",
    "        if not re.match(r\"(TOP|LIMIT)$\", identifier_name, re.IGNORECASE):\n",
    "            identifier_set.add(identifier_name)\n",
    "\n",
    "    def process_function_arguments(token):\n",
    "        if isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token)\n",
    "        elif isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier)\n",
    "        elif isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken)\n",
    "\n",
    "    def add_identifiers_from_function(token):\n",
    "        if not re.match(r\"^(COUNT|SUM|AVG|MIN|MAX|FIRST|LAST)$\", token.get_name(), re.IGNORECASE):\n",
    "            for subtoken in token.tokens:\n",
    "                process_function_arguments(subtoken)\n",
    "\n",
    "    def process_where(token):\n",
    "        for subtoken in token.tokens:\n",
    "            if isinstance(subtoken, sqlparse.sql.Comparison): \n",
    "                process_identifier(subtoken.left)         \n",
    "            elif isinstance(subtoken, sqlparse.sql.Identifier): \n",
    "                process_identifier(subtoken)\n",
    "\n",
    "# Parse the SQL query\n",
    "    parsed_tokens = sqlparse.parse(sql)[0]\n",
    "    identifier_set = set()\n",
    "\n",
    "    for token in parsed_tokens.tokens:\n",
    "        if isinstance(token, sqlparse.sql.Function): \n",
    "            add_identifiers_from_function(token)\n",
    "            continue\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            for identifier in token.get_identifiers():\n",
    "                if isinstance(identifier, sqlparse.sql.Identifier):\n",
    "                    process_identifier(identifier)\n",
    "        elif isinstance(token, sqlparse.sql.Comparison):\n",
    "            process_identifier(token.left)\n",
    "        elif isinstance(token, sqlparse.sql.Where):\n",
    "            process_where(token)\n",
    "        elif isinstance(token, sqlparse.sql.Identifier):\n",
    "            process_identifier(token)\n",
    "\n",
    "    return list(identifier_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['orders',\n",
       " 'order_number',\n",
       " 'client_name',\n",
       " 'order_id',\n",
       " 'revenue_number',\n",
       " 'revenue']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_sql(sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
